#!/bin/bash
# Restart All FindersKeepers v2 Services with GPU Support

set -e

echo "ğŸ”„ Restarting all FindersKeepers v2 services with GPU support..."

# Set Docker socket
export DOCKER_HOST=unix:///var/run/docker.sock

# Stop all existing services
echo "ğŸ›‘ Stopping existing services..."
sudo docker-compose down

# Remove the standalone Ollama container (we'll use docker-compose version)
echo "ğŸ§¹ Cleaning up standalone containers..."
sudo docker stop ollama 2>/dev/null || true
sudo docker rm ollama 2>/dev/null || true
sudo docker stop portainer 2>/dev/null || true
sudo docker rm portainer 2>/dev/null || true

# Start all services with GPU support
echo "ğŸš€ Starting all services with GPU acceleration..."
sudo docker-compose up -d

# Wait for services to initialize
echo "â³ Waiting for services to start..."
sleep 15

# Check service status
echo "ğŸ“Š Service Status:"
sudo docker-compose ps

# Test key services
echo ""
echo "ğŸ§ª Testing services..."

# Test Ollama API
echo "ğŸ¤– Ollama API:"
curl -s http://localhost:11434/api/version || echo "Not ready yet"

# Test FastAPI
echo "âš¡ FastAPI:"
curl -s http://localhost:8000/health || echo "Not ready yet"

# Restart Portainer with new setup
echo "ğŸ–¥ï¸  Restarting Portainer GUI..."
sudo docker run -d \
  -p 8000:8000 \
  -p 9443:9443 \
  --name portainer \
  --restart=always \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v portainer_data:/data \
  portainer/portainer-ce:latest

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… All services restarted with GPU support!"
echo ""
echo "ğŸ¯ Access Points:"
echo "   â€¢ Ollama API: http://localhost:11434"
echo "   â€¢ FastAPI: http://localhost:8000"
echo "   â€¢ n8n: http://localhost:5678 (admin/finderskeepers2025)"
echo "   â€¢ Neo4j: http://localhost:7474 (neo4j/fk2025neo4j)"
echo "   â€¢ Portainer: https://localhost:9443"
echo ""
echo "ğŸ”¥ Ollama, FastAPI, AND n8n now have RTX 2080 Ti GPU access!"
echo ""
echo "ğŸ¤– GPU-enabled services:"
echo "   â€¢ Ollama: Local LLM inference with GPU"
echo "   â€¢ FastAPI: ML operations and embeddings"  
echo "   â€¢ n8n: AI workflows and image processing"